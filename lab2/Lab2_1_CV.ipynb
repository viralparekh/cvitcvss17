{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Generative Adversarial Networks\n",
    "\n",
    "In this lab, we will explore the generative power of GANs and the meaning of the random input we give to the generator. The lab is divided into four experiments:\n",
    "\n",
    "<ol>\n",
    "<li> Train and test a GAN </li>\n",
    "<li> Explore the 'latent variable space' </li>\n",
    "<li> Arithmetic with latent variables </li>\n",
    "<li> Using InfoGAN architecture to give meaning to latent variables </li>\n",
    "</ol>\n",
    "\n",
    "## 1. Train and test a GAN\n",
    "\n",
    "First, let us try to train a GAN using some training images and observe the images generated by the generator. \n",
    "\n",
    "### Loading the dataset\n",
    "\n",
    "For this experiment, we are using MNIST dataset. To load the dataset, we will use the  <a href=https://github.com/pytorch/vision/tree/master/torchvision>torchvision</a> package. Notice that we are transforming the images to 64x64, because that is what is required by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Scale(64),\n",
    "     transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "     transforms.Normalize((0,), (1,))])\n",
    "trainset = torchvision.datasets.MNIST(root='../data/lab2', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "classes = ('0','1','2','3','4','5','6','7','8','9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST dataset is a dataset of handwritten digits. We will train a network that can generate handwritten digits similar to MNIST dataset. Here are some functions that will help us to see the images: Let us see the kind of images in MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "def imshow_array(img):\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use those functions to explore the MNIST dataset. We will display some random images and their classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Generator network\n",
    "\n",
    "A generative adversarial network consists of a generator network, which generates images and a discriminator network, which determines if the generated image is real(from the database) or fake(generated). The job of the generator is to fool the discriminator into thinking the generated images are the real ones. It does this by bringing the generated images close to the images in the dataset.\n",
    "\n",
    "We will use the DCGAN architecture from <a href=https://github.com/pytorch/examples/blob/master/dcgan/main.py>here</a>.\n",
    "\n",
    "Let us define some parameters and initialize the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "\n",
    "# let us define some parameters\n",
    "workers = 2\n",
    "batchSize=4\n",
    "imageSize=28 #height/width of image\n",
    "nz=10\n",
    "ngf = 64\n",
    "ndf=64\n",
    "niter=1 #number of epochs\n",
    "lr=0.0002 #learning rate\n",
    "beta1=0.5 #beta1 for adam\n",
    "cuda=True\n",
    "ngpu=1 #number of gpus to use\n",
    "outf = './output'\n",
    "manualSeed = 67\n",
    "nc = 1 #number of channels\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define the generator network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "             nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the generator network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what sort of images are generated by netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbatchSize = 64\n",
    "noise = torch.FloatTensor(nbatchSize, nz,1,1)\n",
    "noise.normal_(0,1)\n",
    "noise = Variable(noise)\n",
    "#noise = noise.cuda()\n",
    "output = netG.forward(input=noise)\n",
    "print(output.size())\n",
    "\n",
    "output = output.cpu()\n",
    "output = output.data\n",
    "output = torchvision.utils.make_grid(output)\n",
    "output = output.permute(1,2,0)\n",
    "plt.imshow(output.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images generated are random, as the generator is not trained.\n",
    "\n",
    "### Define the discriminator network\n",
    "\n",
    "Let us now define the discriminator network. We have also defined a criterion as binary cross entropy criterion. This will give us our loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1)\n",
    "    \n",
    "netD = _netD(ngpu)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network\n",
    "\n",
    "For training the GAN, we use ADAM optimiser. Here, we set it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train the network. First we will convert the networks into cuda so that it can run on gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(batchSize, 1, imageSize, imageSize)\n",
    "noise = torch.FloatTensor(batchSize, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "label = torch.FloatTensor(batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "if cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion.cuda()\n",
    "    input, label = input.cuda(), label.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below trains for 100 batches and prints some images generated by the generator. We can see how the images progress by repeatedly running this block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        if i>1000:\n",
    "            print('done 100 iterations')\n",
    "            break\n",
    "            \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu, _ = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "        if cuda:\n",
    "            real_cpu = real_cpu.cuda()\n",
    "        input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        label.resize_(batch_size).fill_(real_label)\n",
    "        inputv = Variable(input)\n",
    "        labelv = Variable(label)\n",
    "\n",
    "        output = netD(inputv)\n",
    "        errD_real = criterion(output, labelv)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        # train with fake\n",
    "        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, labelv)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        labelv = Variable(label.fill_(real_label))  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, labelv)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.data.mean()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # display some generated images for each 200 iterations\n",
    "        if i%100 == 0:\n",
    "            fake = netG(fixed_noise)\n",
    "            fake = fake.data\n",
    "            fake = fake[0:16,:,:,:]\n",
    "            fake = fake.cpu()\n",
    "            fake = torchvision.utils.make_grid(fake)\n",
    "            fake = fake.permute(1,2,0)\n",
    "            plt.imshow(fake.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run it for more iterations to train the network. \n",
    "\n",
    "### Walk through the latent variable space\n",
    "What is the input to the generator and how does it influence the output? Right now, we are giving it random vectors of size 10. Let us see what this vector means. We will slowly change the vector and see how the generated images change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = torch.Tensor(nbatchSize, nz, 1,1)\n",
    "noiseL = torch.FloatTensor(nz).uniform_(-1, 1)\n",
    "noiseR = torch.FloatTensor(nz).uniform_(-1, 1)\n",
    "#do a linear interpolation in Z space between point A and point B\n",
    "#each sample in the mini-batch is a point on the line\n",
    "line  = torch.linspace(0, 1, nbatchSize)\n",
    "\n",
    "for i in range(0, nbatchSize):\n",
    "    noise.select(0, i).copy_(noiseL * line[i] + noiseR * (1 - line[i]))\n",
    "\n",
    "noise = Variable(noise)\n",
    "noise = noise.cuda()\n",
    "output = netG.forward(input=noise)\n",
    "print(output.size())\n",
    "\n",
    "output = output.cpu()\n",
    "output = output.data\n",
    "output = torchvision.utils.make_grid(output)\n",
    "output = output.permute(1,2,0)\n",
    "plt.imshow(output.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "<ol>\n",
    "<li>Pytorch tutorial: http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html</li>\n",
    "<li>Code: https://github.com/pytorch/examples/tree/master/dcgan</li>\n",
    "<li>DCGAN paper: Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015).</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
