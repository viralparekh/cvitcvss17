{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Generative Adversarial Networks\n",
    "\n",
    "## 2. InfoGAN\n",
    "\n",
    "In this lab, we will look at a variant of GAN called InfoGAN.\n",
    "\n",
    "Let us load a pretrained model of InfoGAN that has been trained on MNIST dataset. We are loading only the generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from InfoGAN import InfoGAN_Generator\n",
    "\n",
    "model = torch.load('../data/lab2/InfoGAN_Gen.pt')\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define some functions to help us generate noise as input to the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_noise(n_instance, n_dim=2):\n",
    "    \"\"\"generate n-dim uniform random noise\"\"\"\n",
    "    return torch.Tensor(np.random.uniform(low=-3.0, high=3.0,\n",
    "                                          size=(n_instance, n_dim)))\n",
    "\n",
    "\n",
    "def gen_conti_codes(n_instance, n_conti, mean=0, std=1):\n",
    "    \"\"\"generate gaussian continuous codes with specified mean and std\"\"\"\n",
    "    codes = np.random.randn(n_instance, n_conti) * std + mean\n",
    "    return torch.Tensor(codes)\n",
    "\n",
    "\n",
    "def gen_discrete_code(n_instance, n_discrete, num_category=10):\n",
    "    \"\"\"generate discrete codes with n categories\"\"\"\n",
    "    codes = []\n",
    "    for i in range(n_discrete):\n",
    "        code = np.zeros((n_instance, num_category))\n",
    "        random_cate = np.random.randint(0, num_category, n_instance)\n",
    "        code[range(n_instance), random_cate] = 1\n",
    "        codes.append(code)\n",
    "\n",
    "    codes = np.concatenate(codes, 1)\n",
    "    return torch.Tensor(codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate some random noise vector and see the generated images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "batch_size = 64\n",
    "noise_dim = 10 # size of the entangled noise vector\n",
    "n_conti=2 # number of latent variables controlling the continuous property\n",
    "n_discrete=1 # number of latent variables controlling the discrete property (class label of generated image)\n",
    "\n",
    "num_category=10\n",
    "noises = Variable(gen_noise(batch_size, n_dim=noise_dim))\n",
    "conti_codes = Variable(gen_conti_codes(batch_size, n_conti,\n",
    "                                                   0.0, 0.5))\n",
    "discr_codes = Variable(gen_discrete_code(batch_size, n_discrete,\n",
    "                                                     num_category))\n",
    "print(noises.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the final noise vector is a concatenation of the entangled noise vector, and the latent codes that we trained. \n",
    "\n",
    "Let us pass the noise vector through the generator to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_inputs = torch.cat((noises, conti_codes, discr_codes), 1)\n",
    "fake_inputs = model(gen_inputs)\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "output = fake_inputs.data\n",
    "output = torchvision.utils.make_grid(output)\n",
    "output = output.permute(1,2,0)\n",
    "plt.imshow(output.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next few experiments, we will use noise codes and not vary it from cell to cell. Run the following code to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = noises[1,:]\n",
    "noises = noises.repeat(64,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Meaning of the discrete codes\n",
    "\n",
    "Now, let us see what the discrete codes mean. We will initialize them in a systematic manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discr_codes = Variable(torch.eye(10))\n",
    "discr_codes = discr_codes[0:8,:]\n",
    "discr_codes = discr_codes.repeat(8,1)\n",
    "print(discr_codes.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the previous step to see the images generated.\n",
    "\n",
    "### Meaning of the continuous codes\n",
    "\n",
    "Let us see what the continuous codes mean. In this model, two continuous latent variables are used. We will vary them both and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = torch.linspace(-40,40,8)\n",
    "c1 = np.repeat(c.numpy(), 8)\n",
    "c2 = c.repeat(8)\n",
    "\n",
    "c = np.transpose(np.stack((c1,c2.numpy())))\n",
    "conti_codes = torch.from_numpy(c)\n",
    "conti_codes = Variable(conti_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below will make all the discrete codes same, so that we can see the variations more clearly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discr_codes = Variable(torch.zeros(64,10))\n",
    "discr_codes[:,7] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the code to pass the latent variables through the generator and display the resulting images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References \n",
    "<ol>\n",
    "<li>Paper: Chen, Xi, et al. \"Infogan: Interpretable representation learning by information maximizing generative adversarial nets.\" Advances in Neural Information Processing Systems. 2016.</li>\n",
    "<li>Code used to train the model: https://github.com/AaronYALai/Generative_Adversarial_Networks_PyTorch/tree/master/InfoGAN </li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
