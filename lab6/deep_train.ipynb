{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maxmium number of epochs to train the model\n",
    "max_epoch = 10\n",
    "\n",
    "# number of iterations in each epoch\n",
    "iter_per_epoch = 50\n",
    "\n",
    "# number of samples in each iteration\n",
    "batchSize = 64\n",
    "\n",
    "# gpu option. set 1 if available, else 0\n",
    "gpu = 1\n",
    "\n",
    "# learning rate used for Adam optimizer\n",
    "learn_rate = 0.01\n",
    "\n",
    "# momentum parameter for Adam\n",
    "momentum = 0.9\n",
    "\n",
    "# weight decay\n",
    "weightDecay = 0.0005\n",
    "\n",
    "# left patch is searched for 2*half_range + 1 locations\n",
    "#in the right patch.\n",
    "\n",
    "# If left patch is 37*37, and we consider \n",
    "# right patch of size 37 * (37+2*half_range)\n",
    "\n",
    "half_range = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self, nChannel, max_dips):\n",
    "        super(Net, self).__init__()                        \n",
    "        self.l_max_dips = max_dips\n",
    "        self.conv1 = nn.Conv2d(nChannel, 32, 5)    # first conv layer: 32 filters of size 5x5\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32, 1e-3) # first batch normalization layer\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 32, 5)          # second conv layer: 32 filters of size 5x5\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32, 1e-3) # second normalization layer\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, 5)          # third conv layer: 64 filters of size 5x5\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64, 1e-3) # third batch normalization layer\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(64, 64, 5)          # fourth conv layer: 64 filters of size 5x5\n",
    "        self.batchnorm4 = nn.BatchNorm2d(64, 1e-3) # fourth batch normalization layer\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 64, 5)          # fifth conv layer: 64 filters of size 5x5\n",
    "        self.batchnorm5 = nn.BatchNorm2d(64, 1e-3) # fifth batch normalization layer\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(64, 64, 5)          # sixth conv layer: 64 filters of size 5x5\n",
    "        self.batchnorm6 = nn.BatchNorm2d(64, 1e-3) # sixth batch normalization layer\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(64, 64, 5)          # seventh conv layer: 64 filters of size 5x5\n",
    "        self.batchnorm7 = nn.BatchNorm2d(64, 1e-3) # seventh batch normalization layer\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(64, 64, 5)          # eighth conv layer: 64 filters of size 5x5\n",
    "        self.batchnorm8 = nn.BatchNorm2d(64, 1e-3) # eigth batch normalization layer        \n",
    "            \n",
    "        self.conv9 = nn.Conv2d(64, 64, 5)          # ninth conv layer: 64 filters of size 5x5\n",
    "        self.batchnorm9 = nn.BatchNorm2d(64, 1e-3) # ninth batch normalization layer        \n",
    "        self.logsoftmax = nn.LogSoftmax()                        \n",
    "            \n",
    "    def forward_pass(self, x):\n",
    "        x = self.conv1(x)                \n",
    "        x = F.relu(self.batchnorm1(x))\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.batchnorm3(x))\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.batchnorm4(x))\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(self.batchnorm5(x))\n",
    "        \n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(self.batchnorm6(x))\n",
    "        \n",
    "        x = self.conv7(x)\n",
    "        x = F.relu(self.batchnorm7(x))\n",
    "        \n",
    "        x = self.conv8(x)\n",
    "        x = F.relu(self.batchnorm8(x))\n",
    "        \n",
    "        x = self.conv9(x)\n",
    "        x = self.batchnorm9(x)\n",
    "        return x\n",
    "             \n",
    "    def forward(self, x1, x2):\n",
    "        # forward pass left patch of 37x37\n",
    "        x1 = self.forward_pass(x1)\n",
    "        # forward pass right patch of 37*237\n",
    "        x2 = self.forward_pass(x2)\n",
    "        \n",
    "        # left patch feature vector (1,64) dimension\n",
    "        x1 = x1.view(x1.size(0),1,64)        \n",
    "        \n",
    "        # right patch feature matrix (64, 201) dimension\n",
    "        # at 201 locations        \n",
    "        x2 = x2.squeeze().view(x2.size(0),64,self.l_max_dips)\n",
    "        \n",
    "        # multiply the features to get correlation at 201 location\n",
    "        x3 = x1.bmm(x2).view(x2.size(0),self.l_max_dips)\n",
    "        \n",
    "        # compute log p_i(y_i) of scores\n",
    "        x3 = self.logsoftmax(x3)\n",
    "        \n",
    "        return x1,x2,x3        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# three pixel error\n",
    "def loss_function(x3, t, w):    \n",
    "    error = 0\n",
    "    for i in range(x3.size(0)):          \n",
    "        # scores at ground truth target locations.\n",
    "        # instead of taking single score at exact target location\n",
    "        # take two more locations on either side\n",
    "        # and weigh them.\n",
    "        sc = x3[i,t[i][0]-2:t[i][0]+2+1] \n",
    "        \n",
    "         #class_weight_y_i* log p_i(y_i)\n",
    "        loss_sample = torch.mul(sc, w).sum()        \n",
    "        \n",
    "        error = error - loss_sample\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(3, half_range*2+1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate, eps=1e-08, weight_decay=weightDecay)\n",
    "class_wts = Variable(torch.Tensor([1, 4, 10, 4, 1]))\n",
    "\n",
    "if gpu:\n",
    "    model = model.cuda()\n",
    "    class_wts = class_wts.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm2): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm3): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm4): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm5): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
       "  (conv6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm6): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
       "  (conv7): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm7): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
       "  (conv8): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm8): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
       "  (conv9): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchnorm9): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True)\n",
       "  (logsoftmax): LogSoftmax ()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epoch = 5\n",
    "from torch.utils.serialization import load_lua\n",
    "model.train() # train mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_patches = load_lua('data/left_patches.t7')\n",
    "right_patches = load_lua('data/right_patches.t7')\n",
    "targets = load_lua('data/targets.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch  0 6940.05801758\n",
      "Loss at epoch  1 5446.15808594\n",
      "Loss at epoch  2 5080.10720703\n",
      "Loss at epoch  3 4862.2950293\n",
      "Loss at epoch  4 4546.17910156\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    train_loss = 0    \n",
    "    for _iter in range(iter_per_epoch):        \n",
    "        \n",
    "        # zero the gradient buffers\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        # sample batch data\n",
    "        id1 = epoch*iter_per_epoch*batchSize +  _iter*batchSize\n",
    "        id2 = epoch*iter_per_epoch*batchSize + (_iter+1)*batchSize        \n",
    "        left_batch = left_patches[id1:id2, :, :, :]\n",
    "        right_batch = right_patches[id1:id2, :, :, :]\n",
    "        t_batch = targets[id1:id2].view(batchSize,1).int()\n",
    "        \n",
    "        # convert to cuda if gpu available\n",
    "        if gpu:\n",
    "            left_batch = left_batch.cuda()\n",
    "            right_batch = right_batch.cuda()\n",
    "            t_batch = t_batch.cuda()\n",
    "         \n",
    "        # forward pass\n",
    "        x1, x2, x3 = model(Variable(left_batch), Variable(right_batch))   \n",
    "        \n",
    "        # compute loss\n",
    "        loss = loss_function(x3, t_batch, class_wts)\n",
    "        \n",
    "        # backward pass. compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss+=loss.data[0]\n",
    "        \n",
    "    print 'Loss at epoch ', epoch, train_loss/iter_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
