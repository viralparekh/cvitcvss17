{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNN architecture for Digit Recognition\n",
    "![digit](images/digit-recognition.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_samples(image, digit):\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['digit']\n",
    "        h, w = image.shape\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        return {'image': img, 'digit': label}\n",
    "\n",
    "class Resize(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        ## Add your Code here ##\n",
    "    \n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['digit']\n",
    "        h, w = image.shape # changed from [:2] to nothing as the images are gray scale\n",
    "        new_h, new_w = self.output_size\n",
    "        \n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "\n",
    "\n",
    "        return {'image': image, 'digit': label}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['digit']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image[np.newaxis,:,:]\n",
    "        return {'image': torch.from_numpy(image).float(), 'digit': (torch.from_numpy(np.array([label])))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ThreeGramDigitDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, gt_file, dataset_root, shuffle = False, transform = None):\n",
    "        \n",
    "        self.dataset_root = dataset_root\n",
    "        self.all_file_names = [x.split(' ')[0] for x in open(gt_file).readlines()]\n",
    "        self.labels = [int(x.split(' ')[1]) for x in open(gt_file).readlines()]\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.all_file_names, self.labels))\n",
    "            random.shuffle(temp)\n",
    "            self.all_file_names, self.labels = zip(*temp)\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_file_names)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.dataset_root, self.all_file_names[idx])\n",
    "        image = io.imread(img_name)\n",
    "        sample = {'image': image, 'digit': self.labels[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ThreeGramDigitDataset('3Gram_ann_train.txt', '../../data/lab1/imgFolders/3Gram_Digits', shuffle = False)\n",
    "\n",
    "#printing the no. of training samples\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(str(sample['digit'])))\n",
    "    ax.axis('off')\n",
    "    show_samples(**sample) # way of passing a dictionary\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = Rescale(256)\n",
    "crop = RandomCrop(64)\n",
    "composed = transforms.Compose([Rescale(99),Resize((64,128))])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure()\n",
    "sample = train_dataset[1]\n",
    "\n",
    "for i, tsfrm in enumerate([scale, composed]):\n",
    "    print(tsfrm)\n",
    "    print(i)\n",
    "    transformed_sample = tsfrm(sample)\n",
    "    print(transformed_sample['image'].shape)\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    show_samples(**transformed_sample)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = ThreeGramDigitDataset('3Gram_ann_train.txt', '../../data/lab1/imgFolders/3Gram_Digits',\n",
    "                                          shuffle = True, transform=transforms.Compose([\n",
    "                                               Resize((64,128)),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "## Add your Code for test dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch the dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=1)\n",
    "\n",
    "## Add your Code for test_dataloader ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "import pdb\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        ## Add your Code for defining parameters for your CNN layer ##\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## Add your Code for defining your CNN architecture ##\n",
    "    \n",
    "model = Net().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "\n",
    "plotIter = 2000\n",
    "plotIterCntr = 0\n",
    "numEpochs = 10\n",
    "trainLoss = np.zeros((plotIter*numEpochs,1))\n",
    "trainIter = np.arange(plotIter*numEpochs)\n",
    "\n",
    "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data['image'], data['digit']\n",
    "        \n",
    "        #get each label separately\n",
    "        labels_1 = torch.div(labels, 100)\n",
    "        labels_2 = torch.div(torch.fmod(labels, 100), 10)\n",
    "        labels_3 = torch.fmod(torch.fmod(labels, 100), 10)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels_1, labels_2, labels_3 = Variable(inputs.cuda()),Variable(labels_1.cuda()), Variable(labels_2.cuda()), Variable(labels_3.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs_1, outputs_2, outputs_3 = model(inputs)\n",
    "        loss = criterion(outputs_1, labels_1[:,0])+criterion(outputs_2, labels_2[:,0])+criterion(outputs_3, labels_3[:,0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if i % plotIter == plotIter-1:    # print every plotIter mini-batches\n",
    "            trainLoss[plotIterCntr] = running_loss / plotIter\n",
    "            plotIterCntr+=1\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / plotIter))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "plt.plot(np.arange(plotIterCntr)*plotIter,trainLoss[0:plotIterCntr], label=\"train\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction of accuracy\n",
    "\n",
    "import pdb\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "#Iterating over the batches returned from testloader\n",
    "for data in test_dataloader:\n",
    "    images, labels = data['image'], data['digit']\n",
    "        \n",
    "    outputs_1, outputs_2, outputs_3 = model(Variable(images.cuda()))\n",
    "    \n",
    "    _, predicted_1 = torch.max(outputs_1.data, 1)\n",
    "    _, predicted_2 = torch.max(outputs_2.data, 1)\n",
    "    _, predicted_3 = torch.max(outputs_3.data, 1)\n",
    "    \n",
    "    predicted = predicted_1.mul(100) + predicted_2*10 + predicted_3\n",
    "    pdb.set_trace()\n",
    "    total += labels.size(0)\n",
    "    labels = labels.cuda()\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 1350 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
