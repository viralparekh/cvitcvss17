{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CNN on CIFAR10 Dataset\n",
    "\n",
    "We begin with building a CNN architecture for image classification task on CIFAR10 dataset. In this first part of the tutorial, we will understand how to arrange the different architectural components of CNN network, defining the appropriate loss, training the network using backpropagation and finally testing it on the test data.\n",
    "\n",
    "To make data loading simple, we would use the torchvision package created as part of PyTorch which has data loaders for standard datasets such as ImageNet, CIFAR10, MNIST and data transformers for XXX\n",
    "\n",
    "### CIFAR10 dataset\n",
    "![CIFAR10](images/cifar10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pdb\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../data/lab1/imgFolders', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../../data/lab1/imgFolders', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        #self.conv1_bn =nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        #self.is_training = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, p=0.2, training=self.is_training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "plotIter = 2000\n",
    "plotIterCntr = 0\n",
    "numEpochs = 1\n",
    "trainLoss = np.zeros((plotIter*numEpochs,1))\n",
    "trainIter = np.arange(plotIter*numEpochs)\n",
    "#plt.ion()\n",
    "\n",
    "net.cuda()\n",
    "#net.is_training = True\n",
    "\n",
    "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % plotIter == plotIter-1:    # print every plotIter mini-batches\n",
    "            trainLoss[plotIterCntr] = running_loss / plotIter\n",
    "            plotIterCntr+=1\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / plotIter))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "plt.plot(np.arange(plotIterCntr)*plotIter,trainLoss[0:plotIterCntr], label=\"train\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = net(Variable(images).cuda())\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j][0]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Prediction of accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "import pdb\n",
    "\n",
    "#net = net.cuda()\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images.cuda()))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    #pdb.set_trace()\n",
    "    labels = labels.cuda()\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Visualization of Layer 1 weights\n",
    "def plot_kernels(tensor, num_cols=6):\n",
    "    if not tensor.ndim==4:\n",
    "        raise Exception(\"assumes a 4D tensor\")\n",
    "    if not tensor.shape[-1]==3:\n",
    "        raise Exception(\"last dim needs to be 3 to plot\")\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = 1+ num_kernels // num_cols\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    for i in range(tensor.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        ax1.imshow(tensor[i])\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "net_cpu = net.cpu()\n",
    "dat = net_cpu.conv1.weight.data.numpy()\n",
    "maxVal = dat.max()\n",
    "minVal = abs(dat.min())\n",
    "maxVal = max(maxVal,minVal)\n",
    "dat = dat / maxVal\n",
    "dat = dat / 2\n",
    "dat = dat + 0.5\n",
    "\n",
    "plot_kernels(dat.transpose((0,2,3,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropouts, Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb \n",
    "class Net_DB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_DB, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        #self.is_training = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #pdb.set_trace()\n",
    "        x = self.pool(self.conv1_bn(x))\n",
    "        #x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, p=0.2, training=self.is_training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net_db = Net_DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.019\n",
      "[1,  4000] loss: 1.706\n",
      "[1,  6000] loss: 1.597\n",
      "[1,  8000] loss: 1.520\n",
      "[1, 10000] loss: 1.452\n",
      "[1, 12000] loss: 1.400\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEPCAYAAAC6Kkg/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74057b3410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_db.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "plotIter = 2000\n",
    "plotIterCntr = 0\n",
    "numEpochs = 1\n",
    "trainLoss = np.zeros((plotIter*numEpochs,1))\n",
    "trainIter = np.arange(plotIter*numEpochs)\n",
    "\n",
    "net_db.cuda()\n",
    "#net_db.is_training = True\n",
    "\n",
    "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net_db(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % plotIter == plotIter-1:    # print every plotIter mini-batches\n",
    "            trainLoss[plotIterCntr] = running_loss / plotIter\n",
    "            plotIterCntr+=1\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / plotIter))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "plt.plot(np.arange(plotIterCntr)*plotIter,trainLoss[0:plotIterCntr], label=\"train\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "#net_db.is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Prediction of accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net_db(Variable(images).cuda())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    pdb.set_trace()\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Todo\n",
    "Q. Train using exponential decay of learning rate.\n",
    "Q. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
